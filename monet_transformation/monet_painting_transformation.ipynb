{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Copy of monet-painting.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2021-09-23T09:30:16.901489Z",
          "iopub.execute_input": "2021-09-23T09:30:16.901765Z",
          "iopub.status.idle": "2021-09-23T09:30:21.935582Z",
          "shell.execute_reply.started": "2021-09-23T09:30:16.901681Z",
          "shell.execute_reply": "2021-09-23T09:30:21.934873Z"
        },
        "trusted": true,
        "id": "ro-ru1MKz13p"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from zipfile import ZipFile\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "from copy import deepcopy\n",
        "from skimage import io\n",
        "from glob import glob\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision import transforms as T\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import vgg19_bn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-23T09:30:24.391708Z",
          "iopub.execute_input": "2021-09-23T09:30:24.392178Z",
          "iopub.status.idle": "2021-09-23T09:30:24.395535Z",
          "shell.execute_reply.started": "2021-09-23T09:30:24.392141Z",
          "shell.execute_reply": "2021-09-23T09:30:24.394895Z"
        },
        "trusted": true,
        "id": "TGGUTj2-z13t"
      },
      "source": [
        "monet_path = '../input/gan-getting-started/monet_jpg/'\n",
        "photo_path = '../input/gan-getting-started/photo_jpg/'\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-23T09:30:33.557142Z",
          "iopub.execute_input": "2021-09-23T09:30:33.558073Z",
          "iopub.status.idle": "2021-09-23T09:30:33.817234Z",
          "shell.execute_reply.started": "2021-09-23T09:30:33.558027Z",
          "shell.execute_reply": "2021-09-23T09:30:33.816233Z"
        },
        "trusted": true,
        "id": "JaskrBooz13u"
      },
      "source": [
        "monet_files = np.array(glob(monet_path + '*.jpg'))\n",
        "photo_files = np.array(glob(photo_path + '*.jpg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# we make the dataset that provides two classes, first is monet paintings and scond is normal images. since there are fewer monet paintings than normal images, we choose random normal images to pair with monet paintings. we also normalize images from both classes."
      ],
      "metadata": {
        "id": "g6KYruh9z1eI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-23T09:30:38.201613Z",
          "iopub.execute_input": "2021-09-23T09:30:38.202136Z",
          "iopub.status.idle": "2021-09-23T09:30:38.206716Z",
          "shell.execute_reply.started": "2021-09-23T09:30:38.202099Z",
          "shell.execute_reply": "2021-09-23T09:30:38.205405Z"
        },
        "trusted": true,
        "id": "HdK0sUaHz13v"
      },
      "source": [
        "class MonetData(Dataset):\n",
        "    def __init__(self, monet_files, photo_files):\n",
        "        self.monet = monet_files\n",
        "        self.photo = photo_files\n",
        "        self.transforms = T.Compose([T.ToTensor(), T.Normalize(0.5, 0.5)])\n",
        "        self.random_choice()\n",
        "    def __len__(self):\n",
        "        return len(self.monet)\n",
        "    def random_choice(self):\n",
        "        self.photo_files = np.random.choice(self.photo, len(self.monet))\n",
        "        np.random.shuffle(self.monet)\n",
        "    def __getitem__(self, idx):\n",
        "        image_a = io.imread(self.monet[idx])\n",
        "        image_b = io.imread(self.photo_files[idx])\n",
        "        image_a = self.transforms(image_a)\n",
        "        image_b = self.transforms(image_b)\n",
        "        if idx == len(self) - 1:\n",
        "            self.random_choice()\n",
        "        return image_a, image_b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-23T09:30:40.067871Z",
          "iopub.execute_input": "2021-09-23T09:30:40.068541Z",
          "iopub.status.idle": "2021-09-23T09:30:40.074685Z",
          "shell.execute_reply.started": "2021-09-23T09:30:40.068506Z",
          "shell.execute_reply": "2021-09-23T09:30:40.073667Z"
        },
        "trusted": true,
        "id": "LDgCjx-xz13v"
      },
      "source": [
        "train_data = MonetData(monet_files, photo_files)\n",
        "train_data = DataLoader(train_data, batch_size = 4, shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# now we should implement the UNet architecture with residual blocks for the generators and a CNN for discriminators."
      ],
      "metadata": {
        "id": "2VW01qk7-4lo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-23T09:30:41.400154Z",
          "iopub.execute_input": "2021-09-23T09:30:41.400828Z",
          "iopub.status.idle": "2021-09-23T09:30:41.404744Z",
          "shell.execute_reply.started": "2021-09-23T09:30:41.400794Z",
          "shell.execute_reply": "2021-09-23T09:30:41.403943Z"
        },
        "trusted": true,
        "id": "pV3MWB6mz13w"
      },
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "    \n",
        "    def __init__(self , in_ch , out_ch):\n",
        "        super(DecoderBlock , self).__init__()\n",
        "        self.deconv = nn.ConvTranspose2d(in_ch , out_ch , kernel_size = 4 , padding = 1 , stride = 2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.bn = nn.InstanceNorm2d(out_ch)\n",
        "        \n",
        "    def forward(self , feat , x):\n",
        "        x = self.deconv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        x = torch.cat((x , feat) , dim = 1)\n",
        "        return x\n",
        "\n",
        "class DecoderBlock1(nn.Module):\n",
        "    \n",
        "    def __init__(self , in_ch , out_ch):\n",
        "        super(DecoderBlock1 , self).__init__()\n",
        "        self.deconv = nn.Upsample(scale_factor = 2, mode = 'bilinear')\n",
        "        self.conv = nn.Conv2d(in_ch, out_ch, kernel_size = 3, padding = 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.bn = nn.InstanceNorm2d(out_ch)\n",
        "        \n",
        "    def forward(self , feat , x):\n",
        "        x = self.deconv(x)\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        x = torch.cat((x , feat) , dim = 1)\n",
        "        return x\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_ch):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_ch, in_ch, kernel_size = 3, padding = 1, padding_mode = 'reflect')\n",
        "        self.bn = nn.InstanceNorm2d(in_ch)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(in_ch, in_ch, kernel_size = 3, padding = 1, padding_mode = 'reflect')\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x1 = x.clone()\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn(x)\n",
        "        return x1 + x\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    \n",
        "    def __init__(self , out_channel):\n",
        "        super(UNet , self).__init__()\n",
        "        self.out_ch = out_channel\n",
        "        self.feature_detector = vgg19_bn(pretrained = True).features\n",
        "        self.enc1 = self.feature_detector[:6]\n",
        "        self.enc2 = self.feature_detector[6:13]\n",
        "        self.enc3 = self.feature_detector[13:26]\n",
        "        self.enc4 = self.feature_detector[26:39]\n",
        "        #self.enc5 = self.feature_detector[39:52]\n",
        "        \n",
        "        self.bottle_neck = nn.Conv2d(512 , 512 , kernel_size = 3 , padding = 1 , stride = 1)\n",
        "        self.res1 = ResidualBlock(512)\n",
        "        self.res2 = ResidualBlock(512)\n",
        "        self.res3 = ResidualBlock(512)\n",
        "        self.res4 = ResidualBlock(512)\n",
        "        \n",
        "        #self.dec1 = DecoderBlock1(512 , 512)\n",
        "        self.dec2 = DecoderBlock1(512 , 256)\n",
        "        self.dec3 = DecoderBlock1(256 + 512 , 128)\n",
        "        self.dec4 = DecoderBlock1(128 + 256 , 64)\n",
        "        self.dec5 = DecoderBlock1(64 + 128 , 32)\n",
        "        \n",
        "        self.output_conv = nn.Conv2d(99 , out_channel , kernel_size = 7 , padding = 3 , stride = 1)\n",
        "        self.tanh = nn.Tanh()\n",
        "        \n",
        "    def forward(self , x1):\n",
        "        f1 = self.enc1(x1)\n",
        "        f2 = self.enc2(f1)\n",
        "        f3 = self.enc3(f2)\n",
        "        f4 = self.enc4(f3)\n",
        "        #f5 = self.enc5(f4)\n",
        "        \n",
        "        x = self.feature_detector[52](f4)\n",
        "        x = self.bottle_neck(x)\n",
        "        x = self.res1(x)\n",
        "        x = self.res2(x)\n",
        "        x = self.res3(x)\n",
        "        x = self.res4(x)\n",
        "        \n",
        "        #x = self.dec1(f5 , x)\n",
        "        x = self.dec2(f4 , x)\n",
        "        x = self.dec3(f3 , x)\n",
        "        x = self.dec4(f2 , x)\n",
        "        x = self.dec5(torch.cat((f1 , x1) , dim = 1) , x)\n",
        "        \n",
        "        x = self.output_conv(x)\n",
        "        x = self.tanh(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-23T09:30:43.063984Z",
          "iopub.execute_input": "2021-09-23T09:30:43.064241Z",
          "iopub.status.idle": "2021-09-23T09:30:43.071738Z",
          "shell.execute_reply.started": "2021-09-23T09:30:43.064213Z",
          "shell.execute_reply": "2021-09-23T09:30:43.070624Z"
        },
        "trusted": true,
        "id": "XcO6iiV7z13w"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.conv1_1 = nn.Conv2d(3, 64, kernel_size = 3, padding = 1, stride = 1)\n",
        "        self.bn1_1 = nn.BatchNorm2d(64)\n",
        "        self.relu1_1 = nn.LeakyReLU()\n",
        "        self.conv1_2  = nn.Conv2d(64, 64, kernel_size = 3, padding = 1, stride = 2)\n",
        "        self.bn1_2 = nn.BatchNorm2d(64)\n",
        "        self.relu1_2 = nn.LeakyReLU()\n",
        "        \n",
        "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size = 3, padding = 1, stride = 1)\n",
        "        self.bn2_1 = nn.BatchNorm2d(128)\n",
        "        self.relu2_1 = nn.LeakyReLU()\n",
        "        self.conv2_2  = nn.Conv2d(128, 128, kernel_size = 3, padding = 1, stride = 2)\n",
        "        self.bn2_2 = nn.BatchNorm2d(128)\n",
        "        self.relu2_2 = nn.LeakyReLU()\n",
        "        \n",
        "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size = 3, padding = 1, stride = 1)\n",
        "        self.bn3_1 = nn.BatchNorm2d(256)\n",
        "        self.relu3_1 = nn.LeakyReLU()\n",
        "        self.conv3_2  = nn.Conv2d(256, 256, kernel_size = 3, padding = 1, stride = 2)\n",
        "        self.bn3_2 = nn.BatchNorm2d(256)\n",
        "        self.relu3_2 = nn.LeakyReLU()\n",
        "        \n",
        "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size = 3, padding = 1, stride = 1)\n",
        "        self.bn4_1 = nn.BatchNorm2d(512)\n",
        "        self.relu4_1 = nn.LeakyReLU()\n",
        "        self.conv4_2  = nn.Conv2d(512, 512, kernel_size = 3, padding = 1, stride = 2)\n",
        "        self.bn4_2 = nn.BatchNorm2d(512)\n",
        "        self.relu4_2 = nn.LeakyReLU()\n",
        "        \n",
        "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size = 3, padding = 1, stride = 1)\n",
        "        self.bn5_1 = nn.BatchNorm2d(512)\n",
        "        self.relu5_1 = nn.LeakyReLU()\n",
        "        self.conv5_2  = nn.Conv2d(512, 1, kernel_size = 1, padding = 1, stride = 2)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1_1(x)\n",
        "        x = self.bn1_1(x)\n",
        "        x = self.relu1_1(x)\n",
        "        x = self.conv1_2(x)\n",
        "        x = self.bn1_2(x)\n",
        "        x = self.relu1_2(x)\n",
        "\n",
        "        x = self.conv2_1(x)\n",
        "        x = self.bn2_1(x)\n",
        "        x = self.relu2_1(x)\n",
        "        x = self.conv2_2(x)\n",
        "        x = self.bn2_2(x)\n",
        "        x = self.relu2_2(x)\n",
        "\n",
        "        x = self.conv3_1(x)\n",
        "        x = self.bn3_1(x)\n",
        "        x = self.relu3_1(x)\n",
        "        x = self.conv3_2(x)\n",
        "        x = self.bn3_2(x)\n",
        "        x = self.relu3_2(x)\n",
        "\n",
        "        x = self.conv4_1(x)\n",
        "        x = self.bn4_1(x)\n",
        "        x = self.relu4_1(x)\n",
        "        x = self.conv4_2(x)\n",
        "        x = self.bn4_2(x)\n",
        "        x = self.relu4_2(x)\n",
        "\n",
        "        x = self.conv5_1(x)\n",
        "        x = self.bn5_1(x)\n",
        "        x = self.relu5_1(x)\n",
        "        x = self.conv5_2(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-23T09:30:44.602027Z",
          "iopub.execute_input": "2021-09-23T09:30:44.603523Z",
          "iopub.status.idle": "2021-09-23T09:30:44.636085Z",
          "shell.execute_reply.started": "2021-09-23T09:30:44.603481Z",
          "shell.execute_reply": "2021-09-23T09:30:44.635348Z"
        },
        "trusted": true,
        "id": "MUNuasrFz13x"
      },
      "source": [
        "def show_tensor_images(image_tensor, num_images=25, size=(3, 256, 256)):\n",
        "    '''\n",
        "    Function for visualizing images: Given a tensor of images, number of images, and\n",
        "    size per image, plots and prints the images in an uniform grid.\n",
        "    '''\n",
        "    image_tensor = (image_tensor + 1) / 2\n",
        "    image_shifted = image_tensor\n",
        "    image_unflat = image_shifted.detach().cpu().view(-1, *size)\n",
        "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
        "    plt.figure(figsize = (30, 30))\n",
        "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# in this step we define all the loss functions that we need for training the Cycle GAN. these loss functions are, discriminator loss, adversarial loss, identity loss and consistency loss."
      ],
      "metadata": {
        "id": "Y18DSriVKW_J"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-23T09:30:45.457159Z",
          "iopub.execute_input": "2021-09-23T09:30:45.457492Z",
          "iopub.status.idle": "2021-09-23T09:30:45.476433Z",
          "shell.execute_reply.started": "2021-09-23T09:30:45.457462Z",
          "shell.execute_reply": "2021-09-23T09:30:45.4757Z"
        },
        "trusted": true,
        "id": "adXPfx0kz13z"
      },
      "source": [
        "def get_disc_loss(disc_a, real_a, fake_a, criterion):\n",
        "    real_pred = disc_a(real_a)\n",
        "    fake_pred = disc_a(fake_a)\n",
        "    real_loss = criterion(real_pred, torch.ones_like(real_pred))\n",
        "    fake_loss = criterion(fake_pred, torch.zeros_like(fake_pred))\n",
        "    loss = (real_loss + fake_loss) / 2\n",
        "    return loss\n",
        "def get_adv_loss(gen_ab, disc_b, real_a, criterion):\n",
        "    fake_b = gen_ab(real_a)\n",
        "    fake_pred = disc_b(fake_b)\n",
        "    loss = criterion(fake_pred, torch.ones_like(fake_pred))\n",
        "    return loss\n",
        "def get_id_loss(gen_ab, real_b, criterion):\n",
        "    fake_b = gen_ab(real_b).detach()\n",
        "    loss = criterion(fake_b, real_b)\n",
        "    return loss\n",
        "def get_consist_loss(gen_ab, real_b, fake_a, criterion):\n",
        "    fake_b = gen_ab(fake_a)\n",
        "    loss = criterion(fake_b, real_b)\n",
        "    return loss\n",
        "def get_gen_loss(gen_ab, gen_ba, disc_a, disc_b, real_a, real_b, adv_crit, consist_crit, consist_lambda = 10):\n",
        "    fake_a = gen_ba(real_b).detach()\n",
        "    fake_b = gen_ab(real_a).detach()\n",
        "    adv_loss_a = get_adv_loss(gen_ab, disc_b, real_a, adv_crit)\n",
        "    adv_loss_b = get_adv_loss(gen_ba, disc_a, real_b, adv_crit)\n",
        "    consist_loss_a = get_consist_loss(gen_ab, real_b, fake_a, consist_crit) * consist_lambda\n",
        "    consist_loss_b = get_consist_loss(gen_ba, real_a, fake_b, consist_crit) * consist_lambda\n",
        "    loss = adv_loss_a + adv_loss_b + consist_loss_a + consist_loss_b\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# in Cycle GAN we have two generators and two discriminators and we need two optimizers for discriminators and one optimizer for both of the generators."
      ],
      "metadata": {
        "id": "z6rKm7thHW-B"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-23T09:33:33.744506Z",
          "iopub.execute_input": "2021-09-23T09:33:33.74476Z",
          "iopub.status.idle": "2021-09-23T09:33:33.813065Z",
          "shell.execute_reply.started": "2021-09-23T09:33:33.744732Z",
          "shell.execute_reply": "2021-09-23T09:33:33.81238Z"
        },
        "trusted": true,
        "id": "mI2dBlFKz130"
      },
      "source": [
        "gen_ab = UNet(3)\n",
        "gen_ba = UNet(3)\n",
        "disc_a = Discriminator()\n",
        "disc_b = Discriminator()\n",
        "disc_a_optim = torch.optim.Adam(disc_a.parameters(), lr = 0.0002, betas = (0.5, 0.999))\n",
        "disc_b_optim = torch.optim.Adam(disc_b.parameters(), lr = 0.0002, betas = (0.5, 0.999))\n",
        "gen_optim = torch.optim.Adam(list(gen_ab.parameters()) + list(gen_ba.parameters()), lr = 0.0002, betas = (0.5, 0.999))\n",
        "adv_criterion = nn.MSELoss()\n",
        "consist_criterion = nn.L1Loss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# in this section we train the Cycle GAN and we save the generators."
      ],
      "metadata": {
        "id": "xyPKpZ1MI6tS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-23T09:33:28.816985Z",
          "iopub.execute_input": "2021-09-23T09:33:28.817398Z",
          "iopub.status.idle": "2021-09-23T09:33:28.839722Z",
          "shell.execute_reply.started": "2021-09-23T09:33:28.817364Z",
          "shell.execute_reply": "2021-09-23T09:33:28.838958Z"
        },
        "trusted": true,
        "id": "k6zhN0nKz131"
      },
      "source": [
        "def train_cycle_gan(gen_ab, gen_ba, disc_a, disc_b, dsic_a_optim, disc_b_optim, gen_optim, train_data, adv_crit, consist_crit, epochs, device = device):\n",
        "    gen_ab.to(device)\n",
        "    gen_ba.to(device)\n",
        "    disc_a.to(device)\n",
        "    disc_b.to(device)\n",
        "    for epoch in range(epochs):\n",
        "        mean_disc_loss = 0\n",
        "        mean_gen_loss = 0\n",
        "        for real_a, real_b in tqdm(train_data):\n",
        "            real_a = real_a.to(device)\n",
        "            real_b = real_b.to(device)\n",
        "            \n",
        "            disc_a_optim.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                fake_a = gen_ba(real_b)\n",
        "            disc_a_loss = get_disc_loss(disc_a, real_a, fake_a, adv_crit)\n",
        "            disc_a_loss.backward(retain_graph = True)\n",
        "            disc_a_optim.step()\n",
        "            \n",
        "            disc_b_optim.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                fake_b = gen_ab(real_a)\n",
        "            disc_b_loss = get_disc_loss(disc_b, real_b, fake_b, adv_crit)\n",
        "            disc_b_loss.backward(retain_graph = True)\n",
        "            disc_b_optim.step()\n",
        "            \n",
        "            gen_optim.zero_grad()\n",
        "            gen_loss = get_gen_loss(gen_ab, gen_ba, disc_a, disc_b, real_a, real_b, adv_crit, consist_crit)\n",
        "            gen_loss.backward()\n",
        "            gen_optim.step()\n",
        "            \n",
        "            mean_disc_loss += disc_a_loss.item()\n",
        "            mean_gen_loss += gen_loss.item()\n",
        "        print(f'epoch: {epoch}  gen_loss: {mean_gen_loss/len(train_data)}  disc_loss: {mean_disc_loss/len(train_data)}')\n",
        "        show_tensor_images(torch.cat([real_a, real_b]))\n",
        "        show_tensor_images(torch.cat([fake_b, fake_a]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-23T09:33:37.23714Z",
          "iopub.execute_input": "2021-09-23T09:33:37.237466Z",
          "iopub.status.idle": "2021-09-23T09:34:46.874945Z",
          "shell.execute_reply.started": "2021-09-23T09:33:37.237418Z",
          "shell.execute_reply": "2021-09-23T09:34:46.872823Z"
        },
        "trusted": true,
        "id": "iL24k8Vkz132"
      },
      "source": [
        "train_cycle_gan(gen_ab, gen_ba, disc_a, disc_b, disc_a_optim, disc_b_optim, gen_optim, train_data, adv_criterion, consist_criterion, 40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-23T09:34:51.888613Z",
          "iopub.execute_input": "2021-09-23T09:34:51.88887Z",
          "iopub.status.idle": "2021-09-23T09:34:51.895389Z",
          "shell.execute_reply.started": "2021-09-23T09:34:51.888842Z",
          "shell.execute_reply": "2021-09-23T09:34:51.894478Z"
        },
        "trusted": true,
        "id": "gvVFHP3Fz132"
      },
      "source": [
        "torch.save(gen_ba.state_dict(), './gen_ba.pth')\n",
        "torch.save(gen_ab.state_dict(), './gen_ab.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# at last we test the model to see how it works."
      ],
      "metadata": {
        "id": "FR0sH7kyJFbw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-23T09:34:55.237332Z",
          "iopub.execute_input": "2021-09-23T09:34:55.237606Z",
          "iopub.status.idle": "2021-09-23T09:34:55.257301Z",
          "shell.execute_reply.started": "2021-09-23T09:34:55.237578Z",
          "shell.execute_reply": "2021-09-23T09:34:55.25658Z"
        },
        "trusted": true,
        "id": "ZuFVDo63z133"
      },
      "source": [
        "class TestData(Dataset):\n",
        "    def __init__(self, file_names):\n",
        "        self.files = file_names\n",
        "        self.transforms = T.Compose([T.ToTensor(), T.Normalize(0.5, 0.5)])\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "    def __getitem__(self, idx):\n",
        "        file = self.files[idx]\n",
        "        image = io.imread(file)\n",
        "        image = self.transforms(image)\n",
        "        return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-23T09:35:09.576527Z",
          "iopub.execute_input": "2021-09-23T09:35:09.576784Z",
          "iopub.status.idle": "2021-09-23T09:35:09.794496Z",
          "shell.execute_reply.started": "2021-09-23T09:35:09.576756Z",
          "shell.execute_reply": "2021-09-23T09:35:09.793815Z"
        },
        "trusted": true,
        "id": "bO-J83vpz133"
      },
      "source": [
        "test_data = TestData(photo_files)\n",
        "test_data = DataLoader(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "D49XO4vzz133"
      },
      "source": [
        "file_path = []\n",
        "ind = 0\n",
        "for image in tqdm(test_data):\n",
        "    image = image.to(device)\n",
        "    new_image = Image.fromarray((gen_ba(image)[0].detach().permute(1, 2, 0).cpu().numpy() * 127.5 + 127.5).astype(np.uint8))\n",
        "    path = f'./image_{ind}.jpg'\n",
        "    ind += 1\n",
        "    file_path.append(path)\n",
        "    new_image.save(path)\n",
        "\n",
        "with ZipFile('./images.zip', 'w') as zip:\n",
        "    for path in file_path:\n",
        "        zip.write(path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}